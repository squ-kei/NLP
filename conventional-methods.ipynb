{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n    \nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport zipfile\n\n# Libraries and packages for text (pre-)processing \nimport string\nimport re\nimport nltk","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"with zipfile.ZipFile(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"./\")\n\ndf = pd.read_csv(\"train.csv\")\ndf.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"(159571, 8)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['comment_text'].fillna(\"unknown\", inplace=True)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text cleaning"},{"metadata":{},"cell_type":"markdown","source":"### Lower case"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"text_clean\"] = df[\"comment_text\"].apply(lambda x: x.lower())\ndisplay(df.head())","execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \\\n0             0        0       0       0              0   \n1             0        0       0       0              0   \n2             0        0       0       0              0   \n3             0        0       0       0              0   \n4             0        0       0       0              0   \n\n                                          text_clean  \n0  explanation\\nwhy the edits made under my usern...  \n1  d'aww! he matches this background colour i'm s...  \n2  hey man, i'm really not trying to edit war. it...  \n3  \"\\nmore\\ni can't make any real suggestions on ...  \n4  you, sir, are my hero. any chance you remember...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n      <th>text_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>explanation\\nwhy the edits made under my usern...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d'aww! he matches this background colour i'm s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>hey man, i'm really not trying to edit war. it...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>you, sir, are my hero. any chance you remember...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Contractions"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install contractions","execution_count":11,"outputs":[{"output_type":"stream","text":"Collecting contractions\n  Downloading contractions-0.0.25-py2.py3-none-any.whl (3.2 kB)\nCollecting textsearch\n  Downloading textsearch-0.0.17-py2.py3-none-any.whl (7.5 kB)\nRequirement already satisfied: pyahocorasick in /opt/conda/lib/python3.7/site-packages (from textsearch->contractions) (1.4.0)\nRequirement already satisfied: Unidecode in /opt/conda/lib/python3.7/site-packages (from textsearch->contractions) (1.1.1)\nInstalling collected packages: textsearch, contractions\nSuccessfully installed contractions-0.0.25 textsearch-0.0.17\n\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import contractions\n\ndf[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: contractions.fix(x))","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['comment_text'][2])\nprint(df['text_clean'][2])","execution_count":13,"outputs":[{"output_type":"stream","text":"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\nhey man, I am really not trying to edit war. it is just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. he seems to care more about the formatting than the actual info.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Remove URL and HTTP tags"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_URL(text):\n    \"\"\"\n        Remove URLs from a sample string\n    \"\"\"\n    return re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n\n\ndef remove_html(text):\n    \"\"\"\n        Remove the html in sample text\n    \"\"\"\n    html = re.compile(r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\")\n    return re.sub(html, \"\", text)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: remove_URL(x))\ndf[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: remove_html(x))","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove Non-ASCI"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_non_ascii(text):\n    \"\"\"\n        Remove non-ASCII characters \n    \"\"\"\n    return re.sub(r'[^\\x00-\\x7f]',r'', text)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: remove_non_ascii(x))","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove special characters"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_special_characters(text):\n    \"\"\"\n        Remove special special characters, including symbols, emojis, and other graphic characters\n    \"\"\"\n    emoji_pattern = re.compile(\n        '['\n        u'\\U0001F600-\\U0001F64F'  # emoticons\n        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n        u'\\U00002702-\\U000027B0'\n        u'\\U000024C2-\\U0001F251'\n        ']+',\n        flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: remove_special_characters(x))","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove punctuations"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_punct(text):\n    \"\"\"\n        Remove the punctuation\n    \"\"\"\n#     return re.sub(r'[]!\"$%&\\'()*+,./:;=#@?[\\\\^_`{|}~-]+', \"\", text)\n    return text.translate(str.maketrans('', '', string.punctuation))","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: remove_punct(x))","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_numbers(text):\n    if bool(re.search(r'\\d', text)):\n        text = re.sub('[0-9]{5,}', '#####', text)\n        text = re.sub('[0-9]{4}', '####', text)\n        text = re.sub('[0-9]{3}', '###', text)\n        text = re.sub('[0-9]{2}', '##', text)\n    return text","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: clean_numbers(x))","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correct misspelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from textblob import TextBlob\n#df[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: TextBlob(x).correct())","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing\n\n### Tokenization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import word_tokenize\n\ndf['tokenized'] = df['text_clean'].apply(word_tokenize)\ndf.head()","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \\\n0             0        0       0       0              0   \n1             0        0       0       0              0   \n2             0        0       0       0              0   \n3             0        0       0       0              0   \n4             0        0       0       0              0   \n\n                                          text_clean  \\\n0  explanation\\nwhy the edits made under my usern...   \n1  daww he matches this background colour I am se...   \n2  hey man I am really not trying to edit war it ...   \n3  \\nmore\\ni can not make any real suggestions on...   \n4  you sir are my hero any chance you remember wh...   \n\n                                           tokenized  \n0  [explanation, why, the, edits, made, under, my...  \n1  [daww, he, matches, this, background, colour, ...  \n2  [hey, man, I, am, really, not, trying, to, edi...  \n3  [more, i, can, not, make, any, real, suggestio...  \n4  [you, sir, are, my, hero, any, chance, you, re...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n      <th>text_clean</th>\n      <th>tokenized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>explanation\\nwhy the edits made under my usern...</td>\n      <td>[explanation, why, the, edits, made, under, my...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>daww he matches this background colour I am se...</td>\n      <td>[daww, he, matches, this, background, colour, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>hey man I am really not trying to edit war it ...</td>\n      <td>[hey, man, I, am, really, not, trying, to, edi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>\\nmore\\ni can not make any real suggestions on...</td>\n      <td>[more, i, can, not, make, any, real, suggestio...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>you sir are my hero any chance you remember wh...</td>\n      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Remove stopwords"},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords\n\nstop = set(stopwords.words('english'))\ndf['stopwords_removed'] = df['tokenized'].apply(lambda x: [word for word in x if word not in stop])","execution_count":26,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Lemmatization\nwith or without POS tags"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\n\ndef lemmatize_word(text):\n    \"\"\"\n        Lemmatize the tokenized words\n    \"\"\"\n\n    lemmatizer = WordNetLemmatizer()\n    lemma = [lemmatizer.lemmatize(word, tag) for word, tag in text]\n    return lemma","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\n\ndf['lemmatize_word'] = df['stopwords_removed'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\ndf['lemmatize_word'] = df['lemmatize_word'].apply(lambda x: [word for word in x if word not in stop])\ndf.head()","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \\\n0             0        0       0       0              0   \n1             0        0       0       0              0   \n2             0        0       0       0              0   \n3             0        0       0       0              0   \n4             0        0       0       0              0   \n\n                                          text_clean  \\\n0  explanation\\nwhy the edits made under my usern...   \n1  daww he matches this background colour I am se...   \n2  hey man I am really not trying to edit war it ...   \n3  \\nmore\\ni can not make any real suggestions on...   \n4  you sir are my hero any chance you remember wh...   \n\n                                           tokenized  \\\n0  [explanation, why, the, edits, made, under, my...   \n1  [daww, he, matches, this, background, colour, ...   \n2  [hey, man, I, am, really, not, trying, to, edi...   \n3  [more, i, can, not, make, any, real, suggestio...   \n4  [you, sir, are, my, hero, any, chance, you, re...   \n\n                                   stopwords_removed  \\\n0  [explanation, edits, made, username, hardcore,...   \n1  [daww, matches, background, colour, I, seeming...   \n2  [hey, man, I, really, trying, edit, war, guy, ...   \n3  [make, real, suggestions, improvement, wondere...   \n4                [sir, hero, chance, remember, page]   \n\n                                      lemmatize_word  \n0  [explanation, edits, made, username, hardcore,...  \n1  [daww, match, background, colour, I, seemingly...  \n2  [hey, man, I, really, trying, edit, war, guy, ...  \n3  [make, real, suggestion, improvement, wondered...  \n4                [sir, hero, chance, remember, page]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n      <th>text_clean</th>\n      <th>tokenized</th>\n      <th>stopwords_removed</th>\n      <th>lemmatize_word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>explanation\\nwhy the edits made under my usern...</td>\n      <td>[explanation, why, the, edits, made, under, my...</td>\n      <td>[explanation, edits, made, username, hardcore,...</td>\n      <td>[explanation, edits, made, username, hardcore,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>daww he matches this background colour I am se...</td>\n      <td>[daww, he, matches, this, background, colour, ...</td>\n      <td>[daww, matches, background, colour, I, seeming...</td>\n      <td>[daww, match, background, colour, I, seemingly...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>hey man I am really not trying to edit war it ...</td>\n      <td>[hey, man, I, am, really, not, trying, to, edi...</td>\n      <td>[hey, man, I, really, trying, edit, war, guy, ...</td>\n      <td>[hey, man, I, really, trying, edit, war, guy, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>\\nmore\\ni can not make any real suggestions on...</td>\n      <td>[more, i, can, not, make, any, real, suggestio...</td>\n      <td>[make, real, suggestions, improvement, wondere...</td>\n      <td>[make, real, suggestion, improvement, wondered...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>you sir are my hero any chance you remember wh...</td>\n      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n      <td>[sir, hero, chance, remember, page]</td>\n      <td>[sir, hero, chance, remember, page]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Checkpoint\nsave cleaned dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('cleaned.csv')","execution_count":93,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_blob, test_blob = train_test_split(df,test_size=0.2,random_state=42)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_blob.shape)\nprint(test_blob.shape)","execution_count":30,"outputs":[{"output_type":"stream","text":"(127656, 12)\n(31915, 12)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Feature extraction\nuse TF-IDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, HashingVectorizer\n\n# Since the input already been tokenized, we define an identity tokenizer to be sent to TfidfVectorizer\ndef identity_tokenizer(text):\n    return text\n\ntfidf = TfidfVectorizer(tokenizer=identity_tokenizer,ngram_range=(1,2),min_df=3, max_df=0.9,\n                        stop_words='english', lowercase=False,use_idf=1, smooth_idf=1, sublinear_tf=1)    \ntrain_features = tfidf.fit_transform(train_blob['lemmatize_word'])\ntest_features = tfidf.transform(test_blob['lemmatize_word'])","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_col = list(df.columns[2:8])\ntrain_labels = train_blob[label_col].values\ntest_labels = test_blob[label_col].values","execution_count":32,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NB-logistic"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\ndef pr(y_i, y):\n    p = train_features[y==y_i].sum(0)\n    return (p+1) / ((y==y_i).sum()+1)\n\ndef get_mdl(y):\n    y = y.values\n    r = np.log(pr(1,y) / pr(0,y))\n    m = LogisticRegression(C=4)\n    x_nb = train_features.multiply(r)\n    return m.fit(x_nb, y), r","execution_count":137,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.zeros((len(test_labels), len(label_col)))\n\nfor i, j in enumerate(label_col):\n    print('fit', j)\n    m,r = get_mdl(train_blob[j])\n    preds[:,i] = m.predict(test_features.multiply(r))","execution_count":142,"outputs":[{"output_type":"stream","text":"fit toxic\nfit severe_toxic\nfit obscene\nfit threat\nfit insult\nfit identity_hate\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(test_labels, preds, average='micro')","execution_count":144,"outputs":[{"output_type":"execute_result","execution_count":144,"data":{"text/plain":"0.7080166707526355"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# RandomForest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\n\nrnd_clf = RandomForestClassifier(n_estimators=5000, max_depth=2, n_jobs =-1,max_samples=0.8,max_features=0.5)\n\nrnd_clf.fit(train_features,train_labels)\n","execution_count":54,"outputs":[{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"RandomForestClassifier(max_depth=2, max_features=0.5, max_samples=0.8,\n                       n_estimators=5000, n_jobs=-1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rnd_clf.predict(test_features)\ny_pred.sum(0)","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"array([730,   0, 728,   0, 537,   0])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(test_labels, y_pred, average='micro')","execution_count":57,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"0.3958540081596648"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Obviously, it's still overfitting and needs hyperparameter tuning**"},{"metadata":{},"cell_type":"markdown","source":"# NBSVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC, LinearSVC\n\ndef pr(y_i, y):\n    p = train_features[y==y_i].sum(0)\n    return (p+1) / ((y==y_i).sum()+1)\n\ndef get_mdl2(y):\n    y = y.values\n    r = np.log(pr(1,y) / pr(0,y))\n    m = LinearSVC(C=0.15)\n    x_nb = train_features.multiply(r)\n    return m.fit(x_nb, y), r","execution_count":82,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds2 = np.zeros((len(test_labels), len(label_col)))\n\nfor i, j in enumerate(label_col):\n    print('fit', j)\n    m,r = get_mdl2(train_blob[j])\n    preds2[:,i] = m.predict(test_features.multiply(r))","execution_count":83,"outputs":[{"output_type":"stream","text":"fit toxic\nfit severe_toxic\nfit obscene\nfit threat\nfit insult\nfit identity_hate\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(test_labels, preds2, average='micro')","execution_count":84,"outputs":[{"output_type":"execute_result","execution_count":84,"data":{"text/plain":"0.7124519663151011"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}