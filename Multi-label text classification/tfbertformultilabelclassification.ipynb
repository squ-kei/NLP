{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom transformers import TFBertForSequenceClassification, BertTokenizer, TFBertModel\nimport tensorflow as tf\nimport transformers","execution_count":1,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"./\")\n    \ndf = pd.read_csv(\"train.csv\")\ndf.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset, testset = train_test_split(df, test_size = 0.1,random_state=42)\ntrainset, valset = train_test_split(trainset, test_size = 0.2,random_state=42)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = trainset[\"comment_text\"].to_list()\ny_train = trainset.iloc[:,2:].values","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = testset[\"comment_text\"].to_list()\ny_test = testset.iloc[:,2:].values","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val = valset[\"comment_text\"].tolist()\ny_val = valset.iloc[:,2:].values","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ff3f0bc2861447d92bcca92c0742409"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_seq_length =256\ntrain_encodings= tokenizer(x_train,\n                             add_special_tokens=True,\n                             max_length=max_seq_length,\n                             truncation=True,\n                             padding=True, \n                             return_tensors='tf')\nval_encodings = tokenizer(x_val,\n                             add_special_tokens=True,\n                             max_length=max_seq_length,\n                             truncation=True,\n                             padding=True, \n                             return_tensors='tf')\ntest_encodings = tokenizer(x_test,\n                             add_special_tokens=True,\n                             max_length=max_seq_length,\n                             truncation=True,\n                             padding=True, \n                             return_tensors='tf')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(train_encodings),\n    y_train\n))\nval_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(val_encodings),\n    y_val\n))","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n#issue: it'll train normally, but in the end of the first epoch will raise \n#ValueError: logits and labels must have the same shape ((256, 6) vs (6, 1))","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BertforMultiLabelClassification(tf.keras.Model):\n    def __init__(self,num_labels,dropout=0.3,**kwargs):\n        super().__init__(**kwargs)\n        self.bert = transformers.TFBertModel.from_pretrained('bert-base-uncased',return_dict=False)\n        self.dropout = tf.keras.layers.Dropout(dropout)\n        self.dense = tf.keras.layers.Dense(num_labels,kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),\n                                          bias_initializer=tf.zeros_initializer(),activation=tf.keras.activations.sigmoid)\n    \n    def call(self,inputs):\n        _, output_1= self.bert(inputs)\n        output_2 = self.dropout(output_1)\n        output = self.dense(output_2)\n        return output","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = BertforMultiLabelClassification(6)","execution_count":17,"outputs":[{"output_type":"stream","text":"Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow_addons as tfa\nf1 = tfa.metrics.F1Score(num_classes=1, average='micro',threshold=0.5)\noptimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\nloss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\nmodel.compile(optimizer=optimizer, loss=loss, metrics=['acc',f1])\nhistory = model.fit(train_dataset.shuffle(1000).batch(16), epochs=3,validation_data=val_dataset.batch(16))\n#, batch_size=16","execution_count":26,"outputs":[{"output_type":"stream","text":"Epoch 1/3\n7181/7181 [==============================] - 3923s 546ms/step - loss: 0.0438 - acc: 0.9726 - f1_score: 0.7541 - val_loss: 0.0400 - val_acc: 0.9931 - val_f1_score: 0.7723\nEpoch 2/3\n7181/7181 [==============================] - 3925s 547ms/step - loss: 0.0331 - acc: 0.9742 - f1_score: 0.8108 - val_loss: 0.0406 - val_acc: 0.9929 - val_f1_score: 0.7822\nEpoch 3/3\n7181/7181 [==============================] - 3918s 546ms/step - loss: 0.0268 - acc: 0.9616 - f1_score: 0.8521 - val_loss: 0.0445 - val_acc: 0.9913 - val_f1_score: 0.7829\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(test_encodings),\n    y_test\n))\n\nmodel.evaluate(test_dataset.batch(16))","execution_count":28,"outputs":[{"output_type":"stream","text":"998/998 [==============================] - 178s 179ms/step - loss: 0.0428 - acc: 0.9915 - f1_score: 0.7793\n","name":"stdout"},{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"[0.04282236099243164, 0.9914776086807251, 0.7793024182319641]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights(\"TFBertforMultilabelclassification.h5\",save_format=\"h5\")","execution_count":30,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"==================================================================="}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}